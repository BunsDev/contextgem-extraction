{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell_0",
      "metadata": {},
      "source": [
        "# ContextGem: RatingConcept Extraction with References and Justifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_1",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U contextgem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell_2",
      "metadata": {},
      "source": [
        "To run the extraction, please provide your LLM details in the ``DocumentLLM(...)`` constructor further below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ContextGem: RatingConcept Extraction with References and Justifications\n",
        "\n",
        "import os\n",
        "\n",
        "from contextgem import Document, DocumentLLM, RatingConcept\n",
        "\n",
        "# Sample document text about a software product with various aspects\n",
        "software_review = \"\"\"\n",
        "Software Review: ProjectManager Pro 5.0\n",
        "\n",
        "User Interface: The interface is clean and modern, with intuitive navigation. New users can quickly find what they need without extensive training. The dashboard provides a comprehensive overview of project status.\n",
        "\n",
        "Performance: The application loads quickly even with large projects. Resource-intensive operations like generating reports occasionally cause minor lag on older systems. The mobile app performs exceptionally well, even on limited bandwidth.\n",
        "\n",
        "Features: Project templates are well-designed and cover most common project types. Task dependencies are easily managed, and the Gantt chart visualization is excellent. However, the software lacks advanced risk management tools that competitors offer.\n",
        "\n",
        "Support: The documentation is comprehensive and well-organized. Customer service response time averages 4 hours, which is acceptable but not industry-leading. The knowledge base needs more video tutorials.\n",
        "\"\"\"\n",
        "\n",
        "# Create a Document from the text\n",
        "doc = Document(raw_text=software_review)\n",
        "\n",
        "# Create a RatingConcept with justifications and references enabled\n",
        "usability_rating_concept = RatingConcept(\n",
        "    name=\"Software usability rating\",\n",
        "    description=\"Evaluate the overall usability of the software on a scale of 1-10 based on UI design, intuitiveness, and learning curve\",\n",
        "    rating_scale=(1, 10),\n",
        "    add_justifications=True,  # enable justifications to explain the rating\n",
        "    justification_depth=\"comprehensive\",  # provide detailed reasoning\n",
        "    justification_max_sents=5,  # allow up to 5 sentences for justification\n",
        "    add_references=True,  # include references to source text\n",
        "    reference_depth=\"sentences\",  # reference specific sentences rather than paragraphs\n",
        ")\n",
        "\n",
        "# Attach the concept to the document\n",
        "doc.add_concepts([usability_rating_concept])\n",
        "\n",
        "# Configure DocumentLLM with your API parameters\n",
        "llm = DocumentLLM(\n",
        "    model=\"azure/gpt-4.1\",\n",
        "    api_key=os.getenv(\"CONTEXTGEM_AZURE_OPENAI_API_KEY\"),\n",
        "    api_version=os.getenv(\"CONTEXTGEM_AZURE_OPENAI_API_VERSION\"),\n",
        "    api_base=os.getenv(\"CONTEXTGEM_AZURE_OPENAI_API_BASE\"),\n",
        ")\n",
        "\n",
        "# Extract the concept\n",
        "usability_rating_concept = llm.extract_concepts_from_document(doc)[0]\n",
        "\n",
        "# Print the extracted rating item with justification and references\n",
        "extracted_item = usability_rating_concept.extracted_items[0]\n",
        "print(f\"Software Usability Rating: {extracted_item.value}/10\")\n",
        "print(f\"\\nJustification: {extracted_item.justification}\")\n",
        "print(\"\\nSource references:\")\n",
        "for sent in extracted_item.reference_sentences:\n",
        "    print(f\"- {sent.raw_text}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}